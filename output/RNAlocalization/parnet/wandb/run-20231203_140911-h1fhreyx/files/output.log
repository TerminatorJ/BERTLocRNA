ok
/home/sxr280/BERTLocRNA/scripts
embedding will be saved at: /home/sxr280/BERTLocRNA/embeddings/Parnetembedding
loading the dataset...
input embedding shape torch.Size([2, 256, 8000])
embed_output shape: torch.Size([2, 256, 8000])
mask shape torch.Size([2, 1, 8000])
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 243/243 [00:00<00:00, 354263.42it/s]
Resolving data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 255448.77it/s]
Resolving data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77/77 [00:00<00:00, 231016.74it/s]
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
LightningModel                           [2, 9]                    --
├─CustomizedModel: 1-1                   [2, 9]                    --
│    └─Attention_mask: 2-1               [2, 256, 3]               20,720
│    │    └─Tanh: 3-1                    [2, 80, 8000]             --
│    └─Flatten: 2-2                      [2, 768]                  --
│    └─Embedding: 2-3                    [2, 4]                    76
│    └─Linear: 2-4                       [2, 100]                  76,900
│    └─Actvation: 2-5                    [2, 104]                  --
│    └─Dropout: 2-6                      [2, 104]                  --
│    └─Linear: 2-7                       [2, 9]                    945
│    └─Sigmoid: 2-8                      [2, 9]                    --
==========================================================================================
Total params: 98,641
Trainable params: 98,641
Non-trainable params: 0
Total mult-adds (M): 0.16
==========================================================================================
Input size (MB): 16.45
Forward/backward pass size (MB): 0.00
Params size (MB): 0.31
Estimated Total Size (MB): 16.76
==========================================================================================
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python train_model.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
[2023-12-03 14:09:50,294][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2023-12-03 14:09:50,295][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                                                                 | 0/2 [00:00<?, ?it/s]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Sanity Checking DataLoader 0:  50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 1/2 [00:00<00:00, 36.37it/s]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name    | Type            | Params
--------------------------------------------
0 | network | CustomizedModel | 98.6 K
1 | loss_fn | BCELoss         | 0
--------------------------------------------
98.6 K    Trainable params
0         Non-trainable params
98.6 K    Total params
0.395     Total estimated model params size (MB)
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Epoch 0:   0%|                                                                                                                                                                                                                                                   | 0/1146 [00:00<?, ?it/s]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   0%|                                                                                             | 1/1146 [00:00<06:41,  2.85it/s, loss=2.11, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.569]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   0%|▏                                                                                               | 2/1146 [00:00<08:59,  2.12it/s, loss=2, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.764]
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val categorical_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val categorical_accuracy_strict', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val binary_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (916) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|▏                                                                                               | 2/1146 [00:00<08:59,  2.12it/s, loss=2, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   0%|▏                                                                                            | 3/1146 [00:01<08:19,  2.29it/s, loss=1.91, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   0%|▎                                                                                            | 4/1146 [00:01<07:57,  2.39it/s, loss=1.88, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   0%|▍                                                                                            | 5/1146 [00:02<07:49,  2.43it/s, loss=1.86, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▍                                                                                            | 6/1146 [00:02<07:37,  2.49it/s, loss=1.84, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▌                                                                                            | 7/1146 [00:02<07:14,  2.62it/s, loss=1.83, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▋                                                                                             | 8/1146 [00:03<07:09,  2.65it/s, loss=1.8, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▋                                                                                            | 9/1146 [00:03<07:01,  2.70it/s, loss=1.79, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▊                                                                                           | 10/1146 [00:03<06:59,  2.71it/s, loss=1.79, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▉                                                                                           | 11/1146 [00:03<06:49,  2.77it/s, loss=1.77, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▉                                                                                           | 12/1146 [00:04<06:46,  2.79it/s, loss=1.75, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|█                                                                                           | 13/1146 [00:04<06:48,  2.77it/s, loss=1.74, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|█                                                                                           | 14/1146 [00:05<06:48,  2.77it/s, loss=1.72, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|█▏                                                                                          | 15/1146 [00:05<06:50,  2.76it/s, loss=1.71, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|█▎                                                                                          | 16/1146 [00:05<06:43,  2.80it/s, loss=1.71, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|█▍                                                                                           | 17/1146 [00:06<06:43,  2.80it/s, loss=1.7, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▍                                                                                          | 18/1146 [00:06<06:42,  2.80it/s, loss=1.69, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▌                                                                                          | 19/1146 [00:06<06:31,  2.88it/s, loss=1.68, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▌                                                                                          | 20/1146 [00:06<06:32,  2.87it/s, loss=1.67, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
embed_output shape: torch.Size([8, 256, 8000])                                                            | 21/1146 [00:07<06:32,  2.87it/s, loss=1.63, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▊                                                                                           | 22/1146 [00:07<06:32,  2.87it/s, loss=1.6, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])                                                            | 21/1146 [00:07<06:32,  2.87it/s, loss=1.63, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▊                                                                                          | 23/1146 [00:08<06:31,  2.87it/s, loss=1.58, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▉                                                                                          | 24/1146 [00:08<06:31,  2.87it/s, loss=1.56, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|██                                                                                          | 25/1146 [00:08<06:29,  2.88it/s, loss=1.54, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|██                                                                                          | 26/1146 [00:08<06:25,  2.91it/s, loss=1.52, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▋                                                                                         | 33/1146 [00:11<06:19,  2.93it/s, loss=1.41, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|██▎                                                                                          | 28/1146 [00:09<06:25,  2.90it/s, loss=1.5, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▎                                                                                         | 29/1146 [00:10<06:26,  2.89it/s, loss=1.47, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▍                                                                                         | 30/1146 [00:10<06:29,  2.87it/s, loss=1.45, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▍                                                                                         | 31/1146 [00:10<06:27,  2.88it/s, loss=1.43, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▌                                                                                         | 32/1146 [00:11<06:26,  2.88it/s, loss=1.41, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▋                                                                                         | 33/1146 [00:11<06:26,  2.88it/s, loss=1.39, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▋                                                                                         | 34/1146 [00:11<06:26,  2.88it/s, loss=1.38, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▊                                                                                         | 35/1146 [00:12<06:25,  2.88it/s, loss=1.37, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▉                                                                                         | 36/1146 [00:12<06:25,  2.88it/s, loss=1.34, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▉                                                                                         | 37/1146 [00:12<06:23,  2.89it/s, loss=1.32, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.750]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|███                                                                                         | 38/1146 [00:13<06:22,  2.90it/s, loss=1.31, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]
Epoch 0:   3%|███▏                                                                                         | 39/1146 [00:13<06:22,  2.90it/s, loss=1.3, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|███▏                                                                                        | 40/1146 [00:13<06:21,  2.90it/s, loss=1.28, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▎                                                                                        | 41/1146 [00:14<06:22,  2.89it/s, loss=1.27, v_num=reyx, train categorical_accuracy_step=0.875, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▎                                                                                        | 42/1146 [00:14<06:22,  2.89it/s, loss=1.25, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▍                                                                                        | 43/1146 [00:14<06:21,  2.89it/s, loss=1.24, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▌                                                                                        | 44/1146 [00:15<06:20,  2.90it/s, loss=1.24, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]
Epoch 0:   4%|████                                                                                        | 51/1146 [00:17<06:14,  2.92it/s, loss=1.13, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▋                                                                                         | 46/1146 [00:15<06:20,  2.89it/s, loss=1.2, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▊                                                                                        | 47/1146 [00:16<06:20,  2.89it/s, loss=1.18, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▊                                                                                        | 48/1146 [00:16<06:16,  2.92it/s, loss=1.16, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▉                                                                                        | 49/1146 [00:16<06:16,  2.91it/s, loss=1.14, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|████                                                                                        | 50/1146 [00:17<06:16,  2.91it/s, loss=1.13, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|████                                                                                        | 51/1146 [00:17<06:16,  2.91it/s, loss=1.12, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▏                                                                                        | 52/1146 [00:17<06:16,  2.91it/s, loss=1.1, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▎                                                                                       | 53/1146 [00:18<06:15,  2.91it/s, loss=1.09, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▎                                                                                       | 54/1146 [00:18<06:15,  2.91it/s, loss=1.07, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▍                                                                                       | 55/1146 [00:18<06:15,  2.90it/s, loss=1.05, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▍                                                                                       | 56/1146 [00:19<06:15,  2.90it/s, loss=1.04, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]
Epoch 0:   5%|████▌                                                                                       | 57/1146 [00:19<06:17,  2.88it/s, loss=1.01, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▋                                                                                       | 58/1146 [00:20<06:19,  2.87it/s, loss=1.01, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.750]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▋                                                                                      | 59/1146 [00:20<06:20,  2.86it/s, loss=0.999, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▊                                                                                      | 60/1146 [00:20<06:19,  2.86it/s, loss=0.983, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▉                                                                                       | 61/1146 [00:21<06:20,  2.85it/s, loss=0.97, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]
Epoch 0:   5%|█████                                                                                      | 63/1146 [00:22<06:19,  2.86it/s, loss=0.941, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   6%|█████▏                                                                                      | 64/1146 [00:22<06:19,  2.85it/s, loss=0.93, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   6%|█████▏                                                                                      | 65/1146 [00:22<06:19,  2.85it/s, loss=0.92, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   6%|█████▏                                                                                     | 66/1146 [00:23<06:18,  2.85it/s, loss=0.912, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   6%|█████▎                                                                                     | 67/1146 [00:23<06:17,  2.86it/s, loss=0.896, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]
Epoch 0:   6%|█████▍                                                                                     | 69/1146 [00:24<06:17,  2.86it/s, loss=0.874, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   6%|█████▌                                                                                     | 70/1146 [00:24<06:17,  2.85it/s, loss=0.865, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   6%|█████▋                                                                                     | 71/1146 [00:25<06:18,  2.84it/s, loss=0.851, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]
Epoch 0:   7%|█████▉                                                                                     | 75/1146 [00:27<06:27,  2.76it/s, loss=0.823, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   7%|█████▉                                                                                     | 75/1146 [00:27<06:27,  2.76it/s, loss=0.823, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   7%|██████▍                                                                                    | 81/1146 [00:30<06:39,  2.67it/s, loss=0.755, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   7%|██████▍                                                                                    | 81/1146 [00:30<06:39,  2.67it/s, loss=0.755, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   8%|██████▉                                                                                    | 87/1146 [00:33<06:51,  2.57it/s, loss=0.696, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   8%|███████▍                                                                                   | 93/1146 [00:36<06:57,  2.52it/s, loss=0.655, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   8%|███████▍                                                                                   | 93/1146 [00:36<06:57,  2.52it/s, loss=0.655, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   9%|███████▊                                                                                   | 99/1146 [00:39<07:00,  2.49it/s, loss=0.606, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   9%|████████▏                                                                                 | 105/1146 [00:42<07:05,  2.45it/s, loss=0.578, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   9%|████████▏                                                                                 | 105/1146 [00:42<07:05,  2.45it/s, loss=0.578, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  10%|████████▋                                                                                 | 111/1146 [00:46<07:10,  2.40it/s, loss=0.542, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  10%|█████████▏                                                                                | 117/1146 [00:49<07:18,  2.35it/s, loss=0.519, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  10%|█████████▏                                                                                | 117/1146 [00:49<07:18,  2.35it/s, loss=0.519, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  11%|█████████▋                                                                                | 123/1146 [00:53<07:22,  2.31it/s, loss=0.483, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  11%|█████████▉                                                                                | 127/1146 [00:55<07:25,  2.29it/s, loss=0.467, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  11%|██████████▏                                                                               | 130/1146 [00:57<07:27,  2.27it/s, loss=0.453, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  12%|██████████▍                                                                               | 133/1146 [00:58<07:28,  2.26it/s, loss=0.437, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  12%|██████████▊                                                                               | 137/1146 [01:01<07:29,  2.24it/s, loss=0.444, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.708]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  12%|███████████                                                                               | 141/1146 [01:03<07:30,  2.23it/s, loss=0.435, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  13%|███████████▍                                                                              | 145/1146 [01:05<07:29,  2.22it/s, loss=0.402, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.750, train binary_accuracy_step=0.958]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  13%|███████████▌                                                                              | 148/1146 [01:06<07:29,  2.22it/s, loss=0.391, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  13%|███████████▉                                                                              | 152/1146 [01:08<07:30,  2.21it/s, loss=0.394, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  14%|████████████▎                                                                             | 156/1146 [01:10<07:30,  2.20it/s, loss=0.371, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  14%|████████████▍                                                                             | 159/1146 [01:12<07:31,  2.19it/s, loss=0.355, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  14%|████████████▊                                                                             | 163/1146 [01:14<07:30,  2.18it/s, loss=0.367, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  15%|█████████████                                                                             | 167/1146 [01:16<07:29,  2.18it/s, loss=0.386, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  15%|█████████████▍                                                                            | 171/1146 [01:19<07:30,  2.16it/s, loss=0.394, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  15%|█████████████▋                                                                            | 175/1146 [01:21<07:30,  2.15it/s, loss=0.391, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  16%|██████████████▏                                                                            | 178/1146 [01:22<07:30,  2.15it/s, loss=0.38, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  16%|██████████████▎                                                                           | 182/1146 [01:24<07:29,  2.14it/s, loss=0.372, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  16%|██████████████▌                                                                           | 186/1146 [01:27<07:29,  2.13it/s, loss=0.362, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  17%|██████████████▉                                                                           | 190/1146 [01:29<07:28,  2.13it/s, loss=0.359, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  17%|███████████████▏                                                                          | 194/1146 [01:31<07:27,  2.13it/s, loss=0.357, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  17%|███████████████▌                                                                          | 198/1146 [01:33<07:26,  2.12it/s, loss=0.367, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  18%|███████████████▊                                                                          | 202/1146 [01:35<07:24,  2.12it/s, loss=0.379, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  18%|████████████████▏                                                                         | 206/1146 [01:37<07:23,  2.12it/s, loss=0.382, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  18%|████████████████▍                                                                         | 209/1146 [01:38<07:23,  2.11it/s, loss=0.373, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  19%|████████████████▋                                                                         | 213/1146 [01:40<07:21,  2.11it/s, loss=0.365, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  19%|█████████████████                                                                         | 217/1146 [01:42<07:19,  2.11it/s, loss=0.355, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.944]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  19%|█████████████████▍                                                                        | 222/1146 [01:45<07:19,  2.10it/s, loss=0.345, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  20%|█████████████████▋                                                                        | 225/1146 [01:46<07:17,  2.10it/s, loss=0.343, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  20%|██████████████████                                                                        | 230/1146 [01:49<07:16,  2.10it/s, loss=0.342, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  20%|██████████████████▎                                                                       | 233/1146 [01:51<07:15,  2.10it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  21%|██████████████████▌                                                                       | 237/1146 [01:53<07:14,  2.09it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  21%|██████████████████▉                                                                       | 241/1146 [01:55<07:13,  2.09it/s, loss=0.337, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  21%|███████████████████▏                                                                      | 245/1146 [01:57<07:11,  2.09it/s, loss=0.349, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  22%|███████████████████▌                                                                      | 249/1146 [01:59<07:10,  2.09it/s, loss=0.346, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  22%|████████████████████                                                                       | 253/1146 [02:01<07:09,  2.08it/s, loss=0.36, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  22%|████████████████████                                                                      | 256/1146 [02:03<07:07,  2.08it/s, loss=0.362, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  23%|████████████████████▍                                                                     | 261/1146 [02:05<07:05,  2.08it/s, loss=0.384, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  23%|████████████████████▊                                                                     | 265/1146 [02:07<07:03,  2.08it/s, loss=0.359, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  23%|█████████████████████                                                                     | 268/1146 [02:09<07:03,  2.07it/s, loss=0.353, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  24%|█████████████████████▎                                                                    | 272/1146 [02:11<07:02,  2.07it/s, loss=0.355, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  24%|█████████████████████▋                                                                    | 276/1146 [02:13<07:01,  2.07it/s, loss=0.357, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  24%|█████████████████████▉                                                                    | 280/1146 [02:15<06:59,  2.07it/s, loss=0.355, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  25%|██████████████████████▏                                                                   | 283/1146 [02:17<06:58,  2.06it/s, loss=0.354, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  25%|██████████████████████▌                                                                   | 288/1146 [02:19<06:56,  2.06it/s, loss=0.371, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  25%|██████████████████████▊                                                                   | 291/1146 [02:21<06:55,  2.06it/s, loss=0.366, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  26%|███████████████████████▏                                                                  | 295/1146 [02:23<06:53,  2.06it/s, loss=0.363, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  26%|███████████████████████▍                                                                  | 299/1146 [02:25<06:53,  2.05it/s, loss=0.379, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  26%|███████████████████████▋                                                                  | 302/1146 [02:27<06:51,  2.05it/s, loss=0.373, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  27%|███████████████████████▉                                                                  | 305/1146 [02:28<06:50,  2.05it/s, loss=0.377, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  27%|████████████████████████▎                                                                 | 309/1146 [02:31<06:49,  2.04it/s, loss=0.377, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  27%|████████████████████████▌                                                                 | 313/1146 [02:33<06:47,  2.04it/s, loss=0.389, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  28%|████████████████████████▊                                                                 | 316/1146 [02:34<06:47,  2.04it/s, loss=0.382, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  28%|█████████████████████████▏                                                                | 320/1146 [02:37<06:45,  2.04it/s, loss=0.366, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  28%|█████████████████████████▍                                                                | 324/1146 [02:39<06:44,  2.03it/s, loss=0.357, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  29%|█████████████████████████▋                                                                | 327/1146 [02:40<06:43,  2.03it/s, loss=0.353, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  29%|█████████████████████████▉                                                                | 331/1146 [02:43<06:41,  2.03it/s, loss=0.351, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  29%|██████████████████████████▎                                                               | 335/1146 [02:45<06:39,  2.03it/s, loss=0.342, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  30%|██████████████████████████▌                                                               | 339/1146 [02:47<06:37,  2.03it/s, loss=0.343, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  30%|██████████████████████████▉                                                               | 343/1146 [02:49<06:35,  2.03it/s, loss=0.355, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  30%|███████████████████████████▎                                                              | 347/1146 [02:51<06:34,  2.03it/s, loss=0.351, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  31%|███████████████████████████▌                                                              | 351/1146 [02:53<06:32,  2.03it/s, loss=0.358, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  31%|███████████████████████████▉                                                              | 355/1146 [02:55<06:31,  2.02it/s, loss=0.372, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  31%|████████████████████████████                                                              | 358/1146 [02:57<06:29,  2.02it/s, loss=0.371, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  32%|████████████████████████████▋                                                              | 362/1146 [02:59<06:28,  2.02it/s, loss=0.37, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  32%|████████████████████████████▊                                                             | 367/1146 [03:01<06:26,  2.02it/s, loss=0.363, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  32%|█████████████████████████████                                                             | 370/1146 [03:03<06:24,  2.02it/s, loss=0.366, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  33%|█████████████████████████████▎                                                            | 374/1146 [03:05<06:23,  2.02it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  33%|██████████████████████████████                                                             | 378/1146 [03:07<06:21,  2.01it/s, loss=0.35, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  33%|█████████████████████████████▉                                                            | 381/1146 [03:09<06:20,  2.01it/s, loss=0.346, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  34%|██████████████████████████████▏                                                           | 385/1146 [03:11<06:18,  2.01it/s, loss=0.369, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  34%|██████████████████████████████▌                                                           | 389/1146 [03:13<06:16,  2.01it/s, loss=0.364, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  34%|██████████████████████████████▊                                                           | 393/1146 [03:15<06:15,  2.01it/s, loss=0.366, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  35%|███████████████████████████████                                                           | 396/1146 [03:17<06:14,  2.01it/s, loss=0.365, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  35%|███████████████████████████████▍                                                          | 400/1146 [03:19<06:12,  2.00it/s, loss=0.349, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  35%|███████████████████████████████▋                                                          | 404/1146 [03:21<06:10,  2.00it/s, loss=0.343, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  36%|███████████████████████████████▉                                                          | 407/1146 [03:23<06:09,  2.00it/s, loss=0.335, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  36%|████████████████████████████████▎                                                         | 411/1146 [03:25<06:07,  2.00it/s, loss=0.331, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  36%|████████████████████████████████▌                                                         | 415/1146 [03:27<06:05,  2.00it/s, loss=0.331, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  37%|████████████████████████████████▉                                                         | 419/1146 [03:29<06:03,  2.00it/s, loss=0.326, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  37%|█████████████████████████████████▏                                                        | 423/1146 [03:31<06:01,  2.00it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  37%|█████████████████████████████████▉                                                         | 427/1146 [03:33<06:00,  2.00it/s, loss=0.34, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  38%|█████████████████████████████████▊                                                        | 431/1146 [03:35<05:58,  2.00it/s, loss=0.345, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  38%|██████████████████████████████████                                                        | 434/1146 [03:37<05:56,  2.00it/s, loss=0.346, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  38%|██████████████████████████████████▍                                                       | 439/1146 [03:39<05:54,  2.00it/s, loss=0.347, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  39%|██████████████████████████████████▊                                                       | 443/1146 [03:41<05:52,  2.00it/s, loss=0.331, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  39%|███████████████████████████████████                                                       | 447/1146 [03:44<05:50,  1.99it/s, loss=0.334, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  39%|███████████████████████████████████▎                                                      | 450/1146 [03:45<05:48,  1.99it/s, loss=0.341, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  40%|███████████████████████████████████▋                                                      | 454/1146 [03:47<05:46,  1.99it/s, loss=0.343, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  40%|███████████████████████████████████▉                                                      | 457/1146 [03:49<05:45,  1.99it/s, loss=0.351, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  40%|████████████████████████████████████▏                                                     | 461/1146 [03:51<05:43,  1.99it/s, loss=0.349, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  41%|████████████████████████████████████▌                                                     | 465/1146 [03:53<05:42,  1.99it/s, loss=0.355, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  41%|████████████████████████████████████▊                                                     | 468/1146 [03:55<05:40,  1.99it/s, loss=0.348, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  41%|█████████████████████████████████████                                                     | 472/1146 [03:57<05:38,  1.99it/s, loss=0.355, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.722]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  42%|█████████████████████████████████████▉                                                     | 477/1146 [03:59<05:36,  1.99it/s, loss=0.35, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  42%|█████████████████████████████████████▋                                                    | 480/1146 [04:01<05:34,  1.99it/s, loss=0.342, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  42%|██████████████████████████████████████                                                    | 484/1146 [04:03<05:32,  1.99it/s, loss=0.329, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  43%|██████████████████████████████████████▎                                                   | 488/1146 [04:05<05:30,  1.99it/s, loss=0.337, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  43%|██████████████████████████████████████▋                                                   | 492/1146 [04:07<05:29,  1.99it/s, loss=0.329, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  43%|██████████████████████████████████████▊                                                   | 495/1146 [04:09<05:27,  1.99it/s, loss=0.333, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  44%|███████████████████████████████████████▏                                                  | 499/1146 [04:11<05:26,  1.98it/s, loss=0.345, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  44%|███████████████████████████████████████▌                                                  | 503/1146 [04:13<05:24,  1.98it/s, loss=0.361, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  44%|███████████████████████████████████████▊                                                  | 507/1146 [04:15<05:22,  1.98it/s, loss=0.362, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  45%|████████████████████████████████████████                                                  | 510/1146 [04:17<05:21,  1.98it/s, loss=0.371, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  45%|████████████████████████████████████████▎                                                 | 514/1146 [04:19<05:19,  1.98it/s, loss=0.358, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  45%|█████████████████████████████████████████▏                                                 | 518/1146 [04:21<05:17,  1.98it/s, loss=0.36, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  46%|████████████████████████████████████████▉                                                 | 522/1146 [04:23<05:15,  1.98it/s, loss=0.355, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  46%|█████████████████████████████████████████▎                                                | 526/1146 [04:26<05:13,  1.98it/s, loss=0.353, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  46%|█████████████████████████████████████████▌                                                | 529/1146 [04:27<05:12,  1.98it/s, loss=0.348, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  47%|█████████████████████████████████████████▊                                                | 533/1146 [04:29<05:09,  1.98it/s, loss=0.345, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  47%|██████████████████████████████████████████▏                                               | 537/1146 [04:31<05:07,  1.98it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  47%|██████████████████████████████████████████▍                                               | 541/1146 [04:33<05:05,  1.98it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  48%|██████████████████████████████████████████▊                                               | 545/1146 [04:35<05:03,  1.98it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  48%|███████████████████████████████████████████                                               | 549/1146 [04:37<05:01,  1.98it/s, loss=0.334, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  48%|███████████████████████████████████████████▍                                              | 553/1146 [04:39<05:00,  1.98it/s, loss=0.341, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  49%|███████████████████████████████████████████▋                                              | 557/1146 [04:41<04:57,  1.98it/s, loss=0.343, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  49%|████████████████████████████████████████████                                              | 561/1146 [04:43<04:55,  1.98it/s, loss=0.343, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  49%|████████████████████████████████████████████▎                                             | 565/1146 [04:45<04:53,  1.98it/s, loss=0.347, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  50%|████████████████████████████████████████████▋                                             | 569/1146 [04:47<04:51,  1.98it/s, loss=0.348, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  50%|█████████████████████████████████████████████                                             | 573/1146 [04:50<04:50,  1.98it/s, loss=0.354, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  50%|█████████████████████████████████████████████▎                                            | 577/1146 [04:52<04:48,  1.97it/s, loss=0.337, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  51%|██████████████████████████████████████████████                                             | 580/1146 [04:53<04:46,  1.97it/s, loss=0.34, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  51%|█████████████████████████████████████████████▊                                            | 583/1146 [04:55<04:45,  1.97it/s, loss=0.347, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  51%|██████████████████████████████████████████████                                            | 587/1146 [04:57<04:43,  1.97it/s, loss=0.339, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  52%|██████████████████████████████████████████████▍                                           | 591/1146 [04:59<04:41,  1.97it/s, loss=0.334, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  52%|██████████████████████████████████████████████▋                                           | 595/1146 [05:01<04:39,  1.97it/s, loss=0.336, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  52%|███████████████████████████████████████████████                                           | 599/1146 [05:03<04:37,  1.97it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  53%|███████████████████████████████████████████████▎                                          | 603/1146 [05:05<04:35,  1.97it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  53%|███████████████████████████████████████████████▋                                          | 607/1146 [05:07<04:33,  1.97it/s, loss=0.343, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  53%|███████████████████████████████████████████████▉                                          | 611/1146 [05:09<04:31,  1.97it/s, loss=0.345, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  54%|████████████████████████████████████████████████▏                                         | 614/1146 [05:11<04:29,  1.97it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  54%|████████████████████████████████████████████████▌                                         | 619/1146 [05:13<04:27,  1.97it/s, loss=0.327, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  54%|████████████████████████████████████████████████▉                                         | 623/1146 [05:16<04:25,  1.97it/s, loss=0.337, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  55%|█████████████████████████████████████████████████▏                                        | 626/1146 [05:17<04:23,  1.97it/s, loss=0.335, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  55%|█████████████████████████████████████████████████▍                                        | 630/1146 [05:19<04:21,  1.97it/s, loss=0.351, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  55%|█████████████████████████████████████████████████▊                                        | 634/1146 [05:21<04:19,  1.97it/s, loss=0.362, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  56%|██████████████████████████████████████████████████                                        | 638/1146 [05:23<04:17,  1.97it/s, loss=0.373, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.944]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  56%|██████████████████████████████████████████████████▍                                       | 642/1146 [05:25<04:15,  1.97it/s, loss=0.366, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  56%|██████████████████████████████████████████████████▋                                       | 646/1146 [05:28<04:13,  1.97it/s, loss=0.365, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  57%|███████████████████████████████████████████████████                                       | 650/1146 [05:29<04:11,  1.97it/s, loss=0.352, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  57%|███████████████████████████████████████████████████▎                                      | 654/1146 [05:31<04:09,  1.97it/s, loss=0.347, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  57%|███████████████████████████████████████████████████▋                                      | 658/1146 [05:33<04:07,  1.97it/s, loss=0.351, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  58%|████████████████████████████████████████████████████▌                                      | 662/1146 [05:35<04:05,  1.97it/s, loss=0.35, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  58%|████████████████████████████████████████████████████▎                                     | 666/1146 [05:38<04:03,  1.97it/s, loss=0.341, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  58%|████████████████████████████████████████████████████▌                                     | 670/1146 [05:39<04:01,  1.97it/s, loss=0.334, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  59%|████████████████████████████████████████████████████▉                                     | 674/1146 [05:42<03:59,  1.97it/s, loss=0.323, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  59%|█████████████████████████████████████████████████████▏                                    | 678/1146 [05:44<03:57,  1.97it/s, loss=0.339, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  60%|█████████████████████████████████████████████████████▌                                    | 682/1146 [05:46<03:55,  1.97it/s, loss=0.333, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  60%|██████████████████████████████████████████████████████▍                                    | 685/1146 [05:47<03:54,  1.97it/s, loss=0.34, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  60%|██████████████████████████████████████████████████████                                    | 689/1146 [05:50<03:52,  1.97it/s, loss=0.345, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  60%|██████████████████████████████████████████████████████▍                                   | 693/1146 [05:52<03:50,  1.97it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  61%|██████████████████████████████████████████████████████▋                                   | 697/1146 [05:54<03:48,  1.97it/s, loss=0.328, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  61%|███████████████████████████████████████████████████████                                   | 701/1146 [05:56<03:46,  1.97it/s, loss=0.331, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  62%|███████████████████████████████████████████████████████▎                                  | 705/1146 [05:57<03:43,  1.97it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  62%|███████████████████████████████████████████████████████▋                                  | 709/1146 [06:00<03:42,  1.97it/s, loss=0.334, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  62%|███████████████████████████████████████████████████████▉                                  | 713/1146 [06:02<03:40,  1.97it/s, loss=0.331, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  63%|████████████████████████████████████████████████████████▎                                 | 717/1146 [06:04<03:38,  1.97it/s, loss=0.335, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  63%|████████████████████████████████████████████████████████▌                                 | 720/1146 [06:06<03:36,  1.97it/s, loss=0.334, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  63%|████████████████████████████████████████████████████████▊                                 | 724/1146 [06:08<03:34,  1.97it/s, loss=0.331, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  63%|█████████████████████████████████████████████████████████                                 | 727/1146 [06:09<03:33,  1.97it/s, loss=0.352, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  64%|█████████████████████████████████████████████████████████▍                                | 732/1146 [06:12<03:30,  1.97it/s, loss=0.352, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  64%|█████████████████████████████████████████████████████████▋                                | 735/1146 [06:13<03:29,  1.97it/s, loss=0.357, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  64%|█████████████████████████████████████████████████████████▉                                | 738/1146 [06:15<03:27,  1.96it/s, loss=0.343, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  65%|██████████████████████████████████████████████████████████▎                               | 742/1146 [06:17<03:25,  1.96it/s, loss=0.346, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  65%|██████████████████████████████████████████████████████████▌                               | 746/1146 [06:19<03:23,  1.96it/s, loss=0.342, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  65%|██████████████████████████████████████████████████████████▉                               | 750/1146 [06:21<03:21,  1.96it/s, loss=0.336, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  66%|███████████████████████████████████████████████████████████▏                              | 754/1146 [06:24<03:19,  1.96it/s, loss=0.322, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  66%|███████████████████████████████████████████████████████████▍                              | 757/1146 [06:25<03:18,  1.96it/s, loss=0.329, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  66%|███████████████████████████████████████████████████████████▊                              | 762/1146 [06:28<03:15,  1.96it/s, loss=0.316, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  67%|████████████████████████████████████████████████████████████                              | 765/1146 [06:29<03:14,  1.96it/s, loss=0.301, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  67%|████████████████████████████████████████████████████████████▍                             | 769/1146 [06:31<03:12,  1.96it/s, loss=0.302, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  68%|████████████████████████████████████████████████████████████▊                             | 774/1146 [06:34<03:09,  1.96it/s, loss=0.302, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  68%|█████████████████████████████████████████████████████████████                             | 777/1146 [06:35<03:07,  1.96it/s, loss=0.302, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  68%|█████████████████████████████████████████████████████████████▎                            | 781/1146 [06:37<03:05,  1.96it/s, loss=0.314, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  69%|█████████████████████████████████████████████████████████████▋                            | 786/1146 [06:39<03:03,  1.97it/s, loss=0.321, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.750, train binary_accuracy_step=0.972]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  69%|██████████████████████████████████████████████████████████████                            | 790/1146 [06:41<03:01,  1.97it/s, loss=0.341, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  69%|███████████████████████████████████████████████████████████████                            | 794/1146 [06:43<02:59,  1.97it/s, loss=0.36, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  70%|███████████████████████████████████████████████████████████████▍                           | 799/1146 [06:46<02:56,  1.97it/s, loss=0.36, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  70%|███████████████████████████████████████████████████████████████▊                           | 803/1146 [06:48<02:54,  1.97it/s, loss=0.36, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  70%|███████████████████████████████████████████████████████████████▍                          | 807/1146 [06:50<02:52,  1.97it/s, loss=0.363, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  71%|███████████████████████████████████████████████████████████████▋                          | 811/1146 [06:52<02:50,  1.97it/s, loss=0.351, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  71%|████████████████████████████████████████████████████████████████▋                          | 815/1146 [06:54<02:48,  1.97it/s, loss=0.34, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  71%|████████████████████████████████████████████████████████████████▎                         | 819/1146 [06:56<02:46,  1.97it/s, loss=0.324, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  72%|█████████████████████████████████████████████████████████████████▎                         | 823/1146 [06:58<02:44,  1.97it/s, loss=0.33, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  72%|████████████████████████████████████████████████████████████████▉                         | 827/1146 [07:00<02:42,  1.97it/s, loss=0.331, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  73%|█████████████████████████████████████████████████████████████████▎                        | 831/1146 [07:02<02:39,  1.97it/s, loss=0.337, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  73%|█████████████████████████████████████████████████████████████████▋                        | 836/1146 [07:04<02:37,  1.97it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  73%|█████████████████████████████████████████████████████████████████▉                        | 840/1146 [07:06<02:35,  1.97it/s, loss=0.327, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.750, train binary_accuracy_step=0.944]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  74%|██████████████████████████████████████████████████████████████████▎                       | 844/1146 [07:08<02:33,  1.97it/s, loss=0.321, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  74%|██████████████████████████████████████████████████████████████████▌                       | 848/1146 [07:10<02:31,  1.97it/s, loss=0.321, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  74%|██████████████████████████████████████████████████████████████████▉                       | 852/1146 [07:12<02:29,  1.97it/s, loss=0.306, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  75%|███████████████████████████████████████████████████████████████████▎                      | 857/1146 [07:14<02:26,  1.97it/s, loss=0.311, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  75%|███████████████████████████████████████████████████████████████████▌                      | 861/1146 [07:16<02:24,  1.97it/s, loss=0.323, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  75%|███████████████████████████████████████████████████████████████████▊                      | 864/1146 [07:17<02:22,  1.97it/s, loss=0.328, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  76%|████████████████████████████████████████████████████████████████████▏                     | 869/1146 [07:20<02:20,  1.97it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  76%|████████████████████████████████████████████████████████████████████▍                     | 872/1146 [07:21<02:18,  1.97it/s, loss=0.345, v_num=reyx, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  76%|█████████████████████████████████████████████████████████████████████▌                     | 876/1146 [07:23<02:16,  1.97it/s, loss=0.34, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  77%|█████████████████████████████████████████████████████████████████████                     | 880/1146 [07:25<02:14,  1.97it/s, loss=0.342, v_num=reyx, train categorical_accuracy_step=0.875, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  77%|█████████████████████████████████████████████████████████████████████▌                    | 885/1146 [07:28<02:12,  1.97it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  77%|█████████████████████████████████████████████████████████████████████▋                    | 888/1146 [07:29<02:10,  1.97it/s, loss=0.344, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  78%|██████████████████████████████████████████████████████████████████████▏                   | 893/1146 [07:31<02:08,  1.98it/s, loss=0.346, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  78%|███████████████████████████████████████████████████████████████████████▏                   | 897/1146 [07:33<02:05,  1.98it/s, loss=0.35, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  79%|██████████████████████████████████████████████████████████████████████▊                   | 902/1146 [07:36<02:03,  1.98it/s, loss=0.339, v_num=reyx, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  79%|███████████████████████████████████████████████████████████████████████▏                  | 906/1146 [07:38<02:01,  1.98it/s, loss=0.336, v_num=reyx, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  79%|███████████████████████████████████████████████████████████████████████▍                  | 910/1146 [07:40<01:59,  1.98it/s, loss=0.336, v_num=reyx, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  80%|███████████████████████████████████████████████████████████████████████▊                  | 914/1146 [07:42<01:57,  1.98it/s, loss=0.331, v_num=reyx, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  80%|████████████████████████████████████████████████████████████████████████                  | 918/1146 [07:43<01:55,  1.98it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  81%|████████████████████████████████████████████████████████████████████████▌                 | 924/1146 [07:46<01:51,  1.98it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  81%|████████████████████████████████████████████████████████████████████████▉                 | 929/1146 [07:47<01:49,  1.99it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  82%|█████████████████████████████████████████████████████████████████████████▍                | 935/1146 [07:50<01:46,  1.99it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  82%|█████████████████████████████████████████████████████████████████████████▊                | 940/1146 [07:52<01:43,  1.99it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  82%|██████████████████████████████████████████████████████████████████████████▏               | 945/1146 [07:54<01:40,  1.99it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  83%|██████████████████████████████████████████████████████████████████████████▌               | 950/1146 [07:56<01:38,  2.00it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  83%|███████████████████████████████████████████████████████████████████████████               | 955/1146 [07:57<01:35,  2.00it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  84%|███████████████████████████████████████████████████████████████████████████▍              | 960/1146 [08:00<01:33,  2.00it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  84%|███████████████████████████████████████████████████████████████████████████▊              | 965/1146 [08:02<01:30,  2.00it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  85%|████████████████████████████████████████████████████████████████████████████▏             | 970/1146 [08:04<01:27,  2.00it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  85%|████████████████████████████████████████████████████████████████████████████▌             | 975/1146 [08:05<01:25,  2.01it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  86%|█████████████████████████████████████████████████████████████████████████████             | 981/1146 [08:08<01:22,  2.01it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  86%|█████████████████████████████████████████████████████████████████████████████▍            | 986/1146 [08:10<01:19,  2.01it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  86%|█████████████████████████████████████████████████████████████████████████████▋            | 990/1146 [08:11<01:17,  2.01it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  87%|██████████████████████████████████████████████████████████████████████████████▏           | 995/1146 [08:13<01:14,  2.02it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  87%|█████████████████████████████████████████████████████████████████████████████▋           | 1001/1146 [08:15<01:11,  2.02it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  88%|██████████████████████████████████████████████████████████████████████████████▏          | 1006/1146 [08:17<01:09,  2.02it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  88%|██████████████████████████████████████████████████████████████████████████████▌          | 1011/1146 [08:19<01:06,  2.02it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  89%|██████████████████████████████████████████████████████████████████████████████▉          | 1016/1146 [08:22<01:04,  2.02it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  89%|███████████████████████████████████████████████████████████████████████████████▎         | 1021/1146 [08:24<01:01,  2.03it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  90%|███████████████████████████████████████████████████████████████████████████████▋         | 1026/1146 [08:25<00:59,  2.03it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  90%|████████████████████████████████████████████████████████████████████████████████         | 1031/1146 [08:27<00:56,  2.03it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  90%|████████████████████████████████████████████████████████████████████████████████▌        | 1037/1146 [08:30<00:53,  2.03it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  91%|████████████████████████████████████████████████████████████████████████████████▉        | 1042/1146 [08:32<00:51,  2.04it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  91%|█████████████████████████████████████████████████████████████████████████████████▍       | 1048/1146 [08:34<00:48,  2.04it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  92%|█████████████████████████████████████████████████████████████████████████████████▊       | 1053/1146 [08:36<00:45,  2.04it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  92%|██████████████████████████████████████████████████████████████████████████████████▏      | 1058/1146 [08:38<00:43,  2.04it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  93%|██████████████████████████████████████████████████████████████████████████████████▋      | 1064/1146 [08:40<00:40,  2.05it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  93%|███████████████████████████████████████████████████████████████████████████████████      | 1069/1146 [08:42<00:37,  2.05it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  94%|███████████████████████████████████████████████████████████████████████████████████▍     | 1074/1146 [08:44<00:35,  2.05it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  94%|███████████████████████████████████████████████████████████████████████████████████▊     | 1080/1146 [08:46<00:32,  2.05it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  95%|████████████████████████████████████████████████████████████████████████████████████▎    | 1086/1146 [08:48<00:29,  2.06it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  95%|████████████████████████████████████████████████████████████████████████████████████▊    | 1092/1146 [08:50<00:26,  2.06it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  96%|█████████████████████████████████████████████████████████████████████████████████████▏   | 1097/1146 [08:52<00:23,  2.06it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  96%|█████████████████████████████████████████████████████████████████████████████████████▋   | 1103/1146 [08:54<00:20,  2.06it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  97%|█████████████████████████████████████████████████████████████████████████████████████▉   | 1107/1146 [08:56<00:18,  2.06it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  97%|██████████████████████████████████████████████████████████████████████████████████████▍  | 1113/1146 [08:58<00:15,  2.07it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  98%|██████████████████████████████████████████████████████████████████████████████████████▊  | 1118/1146 [09:00<00:13,  2.07it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  98%|███████████████████████████████████████████████████████████████████████████████████████▎ | 1124/1146 [09:02<00:10,  2.07it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  99%|███████████████████████████████████████████████████████████████████████████████████████▋ | 1129/1146 [09:04<00:08,  2.07it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  99%|████████████████████████████████████████████████████████████████████████████████████████ | 1134/1146 [09:05<00:05,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  99%|████████████████████████████████████████████████████████████████████████████████████████▌| 1140/1146 [09:08<00:02,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  99%|████████████████████████████████████████████████████████████████████████████████████████▌| 1140/1146 [09:08<00:02,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([8, 256, 8000])
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train categorical_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train categorical_accuracy_strict', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train binary_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
[rank: 0] Metric val_loss improved. New best score: 0.325
Epoch 0: 100%|████████████████████████████████████████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
Epoch 0: 100%|████████████████████████████████████████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])████████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])████████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])████████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])████████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])██████████████████████████████████████████████████████▉| 1145/1146 [09:10<00:00,  2.08it/s, loss=0.338, v_num=reyx, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.756]input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
input embedding shape torch.Size([3, 256, 8000])
embed_output shape: torch.Size([3, 256, 8000])
mask shape torch.Size([3, 1, 8000])
[2023-12-03 14:21:05,873][HYDRA] 	#1 : model=base_model task=RNAlocalization embedder=nucleotidetransformer
output dir of this job: /home/sxr280/BERTLocRNA/scripts/../output/RNAlocalization/nucleotidetransformer
/home/sxr280/BERTLocRNA/saved_model/NT  already exists, loading the model locally
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.07s/it]
Some weights of the model checkpoint at /home/sxr280/BERTLocRNA/saved_model/NT were not used when initializing EsmModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of EsmModel were not initialized from the model checkpoint at /home/sxr280/BERTLocRNA/saved_model/NT and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 296/296 [00:00<00:00, 392635.67it/s]
Resolving data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 199222.80it/s]
loading the dataset...
Resolving data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:00<00:00, 197428.43it/s]
Error executing job with overrides: ['model=base_model', 'task=RNAlocalization', 'embedder=parnet']
Traceback (most recent call last):
  File "train_model.py", line 55, in <module>
    train()
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 465, in _run_app
    run_and_report(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 222, in run_and_report
    raise ex
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 219, in run_and_report
    return func()
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 466, in <lambda>
    lambda: hydra.multirun(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 162, in multirun
    ret = sweeper.sweep(arguments=task_overrides)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/core_plugins/basic_sweeper.py", line 182, in sweep
    _ = r.return_value
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "train_model.py", line 52, in train
    Trainer.test(test_dataloader)
  File "/home/sxr280/BERTLocRNA/scripts/../utils/trainer.py", line 262, in test
    self.get_metrics_all(test_loader)
  File "/home/sxr280/BERTLocRNA/scripts/../utils/trainer.py", line 281, in get_metrics_all
    RNA_types = [self.config.RNA_order[i] for i in RNA_types]
  File "/home/sxr280/BERTLocRNA/scripts/../utils/trainer.py", line 281, in <listcomp>
    RNA_types = [self.config.RNA_order[i] for i in RNA_types]
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/omegaconf/listconfig.py", line 218, in __getitem__
    self._format_and_raise(key=index, value=None, cause=e)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/omegaconf/base.py", line 231, in _format_and_raise
    format_and_raise(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/omegaconf/_utils.py", line 899, in format_and_raise
    _raise(ex, cause)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/omegaconf/_utils.py", line 797, in _raise
    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/omegaconf/listconfig.py", line 193, in __getitem__
    self._validate_get(index, None)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/omegaconf/listconfig.py", line 86, in _validate_get
    raise KeyValidationError(
omegaconf.errors.KeyValidationError: ListConfig indices must be integers or slices, not int64
    full_key:
    object_type=list