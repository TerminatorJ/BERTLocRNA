ok
/home/sxr280/BERTLocRNA/scripts
embedding will be saved at: /home/sxr280/BERTLocRNA/embeddings/Parnetembedding
loading the dataset...
Resolving data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 243/243 [00:00<00:00, 409159.32it/s]
Resolving data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 255699.95it/s]
Resolving data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77/77 [00:00<00:00, 298209.98it/s]
input embedding shape torch.Size([2, 256, 8000])
embed_output shape: torch.Size([2, 256, 8000])
mask shape torch.Size([2, 1, 8000])
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python train_model.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
LightningModel                           [2, 9]                    --
├─CustomizedModel: 1-1                   [2, 9]                    --
│    └─Attention_mask: 2-1               [2, 256, 3]               20,720
│    │    └─Tanh: 3-1                    [2, 80, 8000]             --
│    └─Flatten: 2-2                      [2, 768]                  --
│    └─Embedding: 2-3                    [2, 4]                    76
│    └─Linear: 2-4                       [2, 100]                  76,900
│    └─Actvation: 2-5                    [2, 104]                  --
│    └─Dropout: 2-6                      [2, 104]                  --
│    └─Linear: 2-7                       [2, 9]                    945
│    └─Sigmoid: 2-8                      [2, 9]                    --
==========================================================================================
Total params: 98,641
Trainable params: 98,641
Non-trainable params: 0
Total mult-adds (M): 0.16
==========================================================================================
Input size (MB): 16.45
Forward/backward pass size (MB): 0.00
Params size (MB): 0.31
Estimated Total Size (MB): 16.76
==========================================================================================
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------
[2023-12-03 14:30:36,233][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2023-12-03 14:30:36,233][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/sxr280/BERTLocRNA/output/RNAlocalization/parnet/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
  | Name    | Type            | Params
--------------------------------------------
0 | network | CustomizedModel | 98.6 K
1 | loss_fn | BCELoss         | 0
--------------------------------------------
98.6 K    Trainable params
0         Non-trainable params
98.6 K    Total params
0.395     Total estimated model params size (MB)
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val categorical_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val categorical_accuracy_strict', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val binary_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                                                      | 0/2 [00:00<?, ?it/s]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Sanity Checking DataLoader 0:  50%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 1/2 [00:00<00:00, 53.57it/s]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   0%|                                                                                                                                                                                                                                         | 0/573 [00:00<?, ?it/s]
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (458) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|                                                                                                                                                                                                                                         | 0/573 [00:00<?, ?it/s]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   0%|▏                                                                                   | 1/573 [00:01<13:16,  1.39s/it, loss=2.1, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.569]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   0%|▎                                                                                  | 2/573 [00:02<13:35,  1.43s/it, loss=1.98, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▍                                                                                  | 3/573 [00:04<13:30,  1.42s/it, loss=1.92, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▌                                                                                  | 4/573 [00:05<13:12,  1.39s/it, loss=1.85, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▋                                                                                  | 5/573 [00:06<13:03,  1.38s/it, loss=1.85, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|▊                                                                                  | 6/573 [00:08<12:48,  1.36s/it, loss=1.83, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|█                                                                                  | 7/573 [00:09<12:35,  1.34s/it, loss=1.82, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   1%|█▏                                                                                 | 8/573 [00:10<12:34,  1.33s/it, loss=1.81, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▎                                                                                  | 9/573 [00:11<12:22,  1.32s/it, loss=1.8, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▍                                                                                 | 10/573 [00:13<12:19,  1.31s/it, loss=1.8, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▌                                                                                | 11/573 [00:14<12:19,  1.32s/it, loss=1.78, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▋                                                                                | 12/573 [00:15<12:26,  1.33s/it, loss=1.75, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|█▊                                                                                | 13/573 [00:17<12:19,  1.32s/it, loss=1.74, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   2%|██                                                                                | 14/573 [00:18<12:15,  1.32s/it, loss=1.74, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▏                                                                               | 15/573 [00:19<12:03,  1.30s/it, loss=1.73, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▎                                                                               | 16/573 [00:20<11:57,  1.29s/it, loss=1.72, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▍                                                                                | 17/573 [00:21<11:50,  1.28s/it, loss=1.7, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▌                                                                                | 18/573 [00:23<11:50,  1.28s/it, loss=1.7, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.750]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   3%|██▋                                                                               | 19/573 [00:24<11:46,  1.28s/it, loss=1.69, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
embed_output shape: torch.Size([8, 256, 8000])                                                  | 20/573 [00:25<11:41,  1.27s/it, loss=1.68, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])                                                  | 20/573 [00:25<11:41,  1.27s/it, loss=1.68, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███                                                                               | 21/573 [00:26<11:41,  1.27s/it, loss=1.65, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▍                                                                              | 24/573 [00:30<11:30,  1.26s/it, loss=1.59, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▎                                                                               | 23/573 [00:29<11:33,  1.26s/it, loss=1.6, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▍                                                                              | 24/573 [00:30<11:30,  1.26s/it, loss=1.59, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   4%|███▌                                                                              | 25/573 [00:31<11:28,  1.26s/it, loss=1.56, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]
Epoch 0:   5%|███▋                                                                              | 26/573 [00:32<11:25,  1.25s/it, loss=1.54, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|███▊                                                                              | 27/573 [00:33<11:21,  1.25s/it, loss=1.52, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]
Epoch 0:   5%|████                                                                               | 28/573 [00:34<11:19,  1.25s/it, loss=1.5, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▏                                                                             | 29/573 [00:36<11:17,  1.25s/it, loss=1.48, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]
Epoch 0:   5%|████▎                                                                             | 30/573 [00:37<11:13,  1.24s/it, loss=1.46, v_num=zk13, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   5%|████▍                                                                             | 31/573 [00:37<10:59,  1.22s/it, loss=1.46, v_num=zk13, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]
Epoch 0:   6%|████▌                                                                             | 32/573 [00:39<11:07,  1.23s/it, loss=1.43, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   6%|████▊                                                                             | 34/573 [00:41<11:00,  1.23s/it, loss=1.38, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])
mask shape torch.Size([8, 1, 8000])
Epoch 0:   6%|█████                                                                             | 35/573 [00:42<10:46,  1.20s/it, loss=1.38, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]
Epoch 0:   6%|█████▏                                                                            | 36/573 [00:43<10:52,  1.21s/it, loss=1.35, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   7%|█████▍                                                                            | 38/573 [00:46<10:47,  1.21s/it, loss=1.31, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   7%|█████▋                                                                            | 40/573 [00:48<10:42,  1.20s/it, loss=1.27, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   7%|██████                                                                            | 42/573 [00:50<10:36,  1.20s/it, loss=1.23, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   7%|██████                                                                            | 42/573 [00:50<10:36,  1.20s/it, loss=1.23, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   8%|██████▎                                                                            | 44/573 [00:52<10:32,  1.20s/it, loss=1.2, v_num=zk13, train categorical_accuracy_step=0.875, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   8%|██████▌                                                                           | 46/573 [00:54<10:25,  1.19s/it, loss=1.18, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   9%|███████▏                                                                          | 50/573 [00:58<10:11,  1.17s/it, loss=1.13, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   9%|███████▏                                                                          | 50/573 [00:58<10:13,  1.17s/it, loss=1.12, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:   9%|███████▋                                                                          | 54/573 [01:02<09:59,  1.16s/it, loss=1.07, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  10%|████████                                                                          | 56/573 [01:04<09:52,  1.15s/it, loss=1.05, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  10%|████████                                                                          | 56/573 [01:04<09:58,  1.16s/it, loss=1.03, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  10%|████████▎                                                                         | 58/573 [01:06<09:53,  1.15s/it, loss=1.01, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  10%|████████▍                                                                        | 60/573 [01:09<09:50,  1.15s/it, loss=0.991, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  11%|████████▊                                                                        | 62/573 [01:11<09:47,  1.15s/it, loss=0.959, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  11%|█████████                                                                        | 64/573 [01:13<09:44,  1.15s/it, loss=0.936, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  12%|█████████▎                                                                       | 66/573 [01:16<09:44,  1.15s/it, loss=0.906, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  12%|█████████▌                                                                       | 68/573 [01:18<09:42,  1.15s/it, loss=0.884, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  12%|█████████▌                                                                       | 68/573 [01:18<09:42,  1.15s/it, loss=0.884, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  12%|█████████▉                                                                       | 70/573 [01:20<09:41,  1.16s/it, loss=0.857, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  13%|██████████▏                                                                      | 72/573 [01:22<09:37,  1.15s/it, loss=0.824, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  13%|██████████▍                                                                      | 74/573 [01:25<09:34,  1.15s/it, loss=0.795, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  13%|██████████▋                                                                      | 76/573 [01:27<09:29,  1.15s/it, loss=0.781, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  14%|███████████                                                                      | 78/573 [01:29<09:27,  1.15s/it, loss=0.748, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  14%|███████████▎                                                                     | 80/573 [01:31<09:24,  1.15s/it, loss=0.722, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  14%|███████████▌                                                                     | 82/573 [01:33<09:21,  1.14s/it, loss=0.707, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  15%|███████████▊                                                                     | 84/573 [01:35<09:18,  1.14s/it, loss=0.688, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  15%|████████████▏                                                                    | 86/573 [01:38<09:16,  1.14s/it, loss=0.669, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  15%|████████████▍                                                                    | 88/573 [01:40<09:12,  1.14s/it, loss=0.641, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  16%|████████████▋                                                                    | 90/573 [01:42<09:09,  1.14s/it, loss=0.629, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  16%|█████████████                                                                    | 92/573 [01:44<09:05,  1.13s/it, loss=0.622, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  16%|█████████████▎                                                                   | 94/573 [01:46<09:01,  1.13s/it, loss=0.606, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  17%|█████████████▌                                                                   | 96/573 [01:48<08:58,  1.13s/it, loss=0.593, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  17%|█████████████▊                                                                   | 98/573 [01:50<08:55,  1.13s/it, loss=0.586, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  17%|█████████████▉                                                                  | 100/573 [01:52<08:52,  1.13s/it, loss=0.576, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  18%|██████████████▏                                                                 | 102/573 [01:54<08:49,  1.12s/it, loss=0.565, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  18%|██████████████▏                                                                 | 102/573 [01:54<08:49,  1.12s/it, loss=0.565, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  18%|██████████████▉                                                                  | 106/573 [01:58<08:43,  1.12s/it, loss=0.54, v_num=zk13, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  19%|███████████████                                                                 | 108/573 [02:00<08:39,  1.12s/it, loss=0.545, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.708]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  19%|███████████████▎                                                                | 110/573 [02:02<08:36,  1.12s/it, loss=0.522, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  20%|███████████████▋                                                                | 112/573 [02:04<08:34,  1.12s/it, loss=0.501, v_num=zk13, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  20%|███████████████▉                                                                | 114/573 [02:06<08:30,  1.11s/it, loss=0.501, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  20%|████████████████▏                                                               | 116/573 [02:08<08:27,  1.11s/it, loss=0.475, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  20%|████████████████▏                                                               | 116/573 [02:08<08:27,  1.11s/it, loss=0.475, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  21%|████████████████▊                                                               | 120/573 [02:12<08:19,  1.10s/it, loss=0.451, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  21%|████████████████▊                                                               | 120/573 [02:13<08:22,  1.11s/it, loss=0.447, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  21%|█████████████████▏                                                               | 122/573 [02:15<08:19,  1.11s/it, loss=0.44, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  22%|█████████████████▎                                                              | 124/573 [02:17<08:16,  1.11s/it, loss=0.428, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  22%|█████████████████▌                                                              | 126/573 [02:19<08:14,  1.11s/it, loss=0.414, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  22%|█████████████████▊                                                              | 128/573 [02:21<08:12,  1.11s/it, loss=0.396, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  23%|██████████████████▏                                                             | 130/573 [02:23<08:09,  1.11s/it, loss=0.405, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  23%|██████████████████▍                                                             | 132/573 [02:25<08:06,  1.10s/it, loss=0.415, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  23%|██████████████████▋                                                             | 134/573 [02:27<08:04,  1.10s/it, loss=0.398, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  24%|██████████████████▉                                                             | 136/573 [02:30<08:02,  1.10s/it, loss=0.404, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  24%|███████████████████▎                                                            | 138/573 [02:32<07:59,  1.10s/it, loss=0.405, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  24%|███████████████████▌                                                            | 140/573 [02:34<07:56,  1.10s/it, loss=0.407, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  25%|███████████████████▊                                                            | 142/573 [02:36<07:54,  1.10s/it, loss=0.398, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  25%|████████████████████                                                            | 144/573 [02:38<07:51,  1.10s/it, loss=0.398, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  25%|████████████████████▍                                                           | 146/573 [02:40<07:48,  1.10s/it, loss=0.401, v_num=zk13, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  26%|████████████████████▋                                                           | 148/573 [02:42<07:46,  1.10s/it, loss=0.403, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  26%|████████████████████▉                                                           | 150/573 [02:44<07:44,  1.10s/it, loss=0.394, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  27%|█████████████████████▏                                                          | 152/573 [02:46<07:41,  1.10s/it, loss=0.377, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  27%|█████████████████████▌                                                          | 154/573 [02:48<07:38,  1.10s/it, loss=0.377, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  27%|█████████████████████▌                                                          | 154/573 [02:48<07:39,  1.10s/it, loss=0.382, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  27%|█████████████████████▊                                                          | 156/573 [02:51<07:37,  1.10s/it, loss=0.392, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.708]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  28%|██████████████████████                                                          | 158/573 [02:53<07:34,  1.10s/it, loss=0.392, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  28%|██████████████████████▎                                                         | 160/573 [02:55<07:32,  1.10s/it, loss=0.383, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  28%|██████████████████████▌                                                         | 162/573 [02:57<07:30,  1.10s/it, loss=0.388, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  29%|██████████████████████▉                                                         | 164/573 [02:59<07:27,  1.09s/it, loss=0.384, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  29%|███████████████████████▏                                                        | 166/573 [03:01<07:25,  1.09s/it, loss=0.384, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  29%|███████████████████████▍                                                        | 168/573 [03:03<07:22,  1.09s/it, loss=0.378, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  30%|███████████████████████▋                                                        | 170/573 [03:05<07:20,  1.09s/it, loss=0.374, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  30%|████████████████████████                                                        | 172/573 [03:07<07:18,  1.09s/it, loss=0.386, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  30%|████████████████████████▎                                                       | 174/573 [03:10<07:15,  1.09s/it, loss=0.378, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  31%|████████████████████████▌                                                       | 176/573 [03:12<07:13,  1.09s/it, loss=0.364, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  31%|████████████████████████▊                                                       | 178/573 [03:14<07:10,  1.09s/it, loss=0.375, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  31%|█████████████████████████▏                                                      | 180/573 [03:16<07:08,  1.09s/it, loss=0.379, v_num=zk13, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  32%|█████████████████████████▍                                                      | 182/573 [03:18<07:05,  1.09s/it, loss=0.377, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  32%|██████████████████████████                                                       | 184/573 [03:20<07:03,  1.09s/it, loss=0.37, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  32%|█████████████████████████▉                                                      | 186/573 [03:22<07:01,  1.09s/it, loss=0.367, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  33%|██████████████████████████▏                                                     | 188/573 [03:24<06:58,  1.09s/it, loss=0.375, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  33%|██████████████████████████▌                                                     | 190/573 [03:26<06:56,  1.09s/it, loss=0.383, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  34%|██████████████████████████▊                                                     | 192/573 [03:28<06:54,  1.09s/it, loss=0.379, v_num=zk13, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  34%|███████████████████████████                                                     | 194/573 [03:31<06:52,  1.09s/it, loss=0.385, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  34%|███████████████████████████▎                                                    | 196/573 [03:32<06:49,  1.09s/it, loss=0.383, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  34%|███████████████████████████▎                                                    | 196/573 [03:33<06:50,  1.09s/it, loss=0.381, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  35%|███████████████████████████▋                                                    | 198/573 [03:35<06:47,  1.09s/it, loss=0.369, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  35%|███████████████████████████▉                                                    | 200/573 [03:37<06:45,  1.09s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  35%|████████████████████████████▏                                                   | 202/573 [03:39<06:43,  1.09s/it, loss=0.359, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  36%|████████████████████████████▍                                                   | 204/573 [03:42<06:41,  1.09s/it, loss=0.371, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  36%|████████████████████████████▊                                                   | 206/573 [03:44<06:39,  1.09s/it, loss=0.367, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  36%|█████████████████████████████                                                   | 208/573 [03:46<06:37,  1.09s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  37%|█████████████████████████████▎                                                  | 210/573 [03:48<06:34,  1.09s/it, loss=0.343, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  37%|█████████████████████████████▌                                                  | 212/573 [03:50<06:32,  1.09s/it, loss=0.348, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  37%|█████████████████████████████▉                                                  | 214/573 [03:52<06:30,  1.09s/it, loss=0.348, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  37%|█████████████████████████████▉                                                  | 214/573 [03:52<06:30,  1.09s/it, loss=0.348, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  38%|██████████████████████████████▍                                                 | 218/573 [03:57<06:26,  1.09s/it, loss=0.361, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  38%|██████████████████████████████▍                                                 | 218/573 [03:57<06:26,  1.09s/it, loss=0.361, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  38%|██████████████████████████████▋                                                 | 220/573 [03:59<06:23,  1.09s/it, loss=0.368, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  39%|██████████████████████████████▉                                                 | 222/573 [04:01<06:21,  1.09s/it, loss=0.368, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  39%|███████████████████████████████▎                                                | 224/573 [04:03<06:19,  1.09s/it, loss=0.365, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  39%|███████████████████████████████▌                                                | 226/573 [04:05<06:16,  1.09s/it, loss=0.364, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  40%|███████████████████████████████▊                                                | 228/573 [04:07<06:14,  1.08s/it, loss=0.372, v_num=zk13, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  40%|████████████████████████████████                                                | 230/573 [04:09<06:12,  1.08s/it, loss=0.383, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  40%|████████████████████████████████▍                                               | 232/573 [04:11<06:09,  1.08s/it, loss=0.375, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  41%|████████████████████████████████▋                                               | 234/573 [04:13<06:07,  1.08s/it, loss=0.381, v_num=zk13, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  41%|████████████████████████████████▉                                               | 236/573 [04:15<06:05,  1.08s/it, loss=0.376, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  42%|█████████████████████████████████▏                                              | 238/573 [04:17<06:03,  1.08s/it, loss=0.374, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  42%|█████████████████████████████████▌                                              | 240/573 [04:19<06:00,  1.08s/it, loss=0.367, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  42%|█████████████████████████████████▊                                              | 242/573 [04:22<05:58,  1.08s/it, loss=0.364, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  43%|██████████████████████████████████                                              | 244/573 [04:24<05:56,  1.08s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  43%|██████████████████████████████████▎                                             | 246/573 [04:26<05:53,  1.08s/it, loss=0.364, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  43%|██████████████████████████████████▌                                             | 248/573 [04:28<05:51,  1.08s/it, loss=0.365, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  44%|██████████████████████████████████▉                                             | 250/573 [04:30<05:49,  1.08s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  44%|███████████████████████████████████▏                                            | 252/573 [04:32<05:47,  1.08s/it, loss=0.367, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  44%|███████████████████████████████████▍                                            | 254/573 [04:35<05:45,  1.08s/it, loss=0.362, v_num=zk13, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  45%|███████████████████████████████████▋                                            | 256/573 [04:37<05:43,  1.08s/it, loss=0.356, v_num=zk13, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  45%|████████████████████████████████████                                            | 258/573 [04:39<05:40,  1.08s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  45%|████████████████████████████████████▎                                           | 260/573 [04:41<05:38,  1.08s/it, loss=0.367, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  45%|████████████████████████████████████▎                                           | 260/573 [04:41<05:38,  1.08s/it, loss=0.367, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  46%|█████████████████████████████████████                                            | 262/573 [04:43<05:36,  1.08s/it, loss=0.37, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  46%|█████████████████████████████████████▎                                           | 264/573 [04:45<05:34,  1.08s/it, loss=0.38, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  46%|█████████████████████████████████████▏                                          | 266/573 [04:47<05:31,  1.08s/it, loss=0.373, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.944]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  47%|█████████████████████████████████████▍                                          | 268/573 [04:49<05:29,  1.08s/it, loss=0.367, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  47%|█████████████████████████████████████▋                                          | 270/573 [04:51<05:27,  1.08s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  47%|█████████████████████████████████████▉                                          | 272/573 [04:53<05:25,  1.08s/it, loss=0.361, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  48%|██████████████████████████████████████▋                                          | 274/573 [04:56<05:23,  1.08s/it, loss=0.36, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  48%|██████████████████████████████████████▌                                         | 276/573 [04:58<05:20,  1.08s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  49%|██████████████████████████████████████▊                                         | 278/573 [05:00<05:18,  1.08s/it, loss=0.362, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  49%|███████████████████████████████████████                                         | 280/573 [05:02<05:16,  1.08s/it, loss=0.364, v_num=zk13, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  49%|███████████████████████████████████████▎                                        | 282/573 [05:04<05:14,  1.08s/it, loss=0.365, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  50%|███████████████████████████████████████▋                                        | 284/573 [05:06<05:12,  1.08s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  50%|███████████████████████████████████████▉                                        | 286/573 [05:08<05:09,  1.08s/it, loss=0.364, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  50%|████████████████████████████████████████▏                                       | 288/573 [05:10<05:07,  1.08s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  51%|████████████████████████████████████████▍                                       | 290/573 [05:12<05:05,  1.08s/it, loss=0.362, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  51%|████████████████████████████████████████▊                                       | 292/573 [05:15<05:03,  1.08s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  51%|█████████████████████████████████████████                                       | 294/573 [05:17<05:00,  1.08s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  52%|█████████████████████████████████████████▊                                       | 296/573 [05:19<04:58,  1.08s/it, loss=0.36, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  52%|█████████████████████████████████████████▌                                      | 298/573 [05:21<04:56,  1.08s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  52%|█████████████████████████████████████████▌                                      | 298/573 [05:21<04:56,  1.08s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  52%|█████████████████████████████████████████▉                                      | 300/573 [05:23<04:54,  1.08s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  53%|██████████████████████████████████████████▏                                     | 302/573 [05:25<04:52,  1.08s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  53%|██████████████████████████████████████████▍                                     | 304/573 [05:27<04:50,  1.08s/it, loss=0.354, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  53%|██████████████████████████████████████████▋                                     | 306/573 [05:30<04:48,  1.08s/it, loss=0.349, v_num=zk13, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  54%|███████████████████████████████████████████                                     | 308/573 [05:32<04:45,  1.08s/it, loss=0.345, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.625, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  54%|███████████████████████████████████████████▎                                    | 310/573 [05:34<04:43,  1.08s/it, loss=0.343, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  54%|███████████████████████████████████████████▌                                    | 312/573 [05:36<04:41,  1.08s/it, loss=0.354, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  55%|███████████████████████████████████████████▊                                    | 314/573 [05:38<04:39,  1.08s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  55%|████████████████████████████████████████████                                    | 316/573 [05:40<04:37,  1.08s/it, loss=0.362, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  55%|████████████████████████████████████████████▍                                   | 318/573 [05:42<04:34,  1.08s/it, loss=0.365, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  56%|████████████████████████████████████████████▋                                   | 320/573 [05:44<04:32,  1.08s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  56%|████████████████████████████████████████████▉                                   | 322/573 [05:46<04:30,  1.08s/it, loss=0.352, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  57%|█████████████████████████████████████████████▏                                  | 324/573 [05:49<04:28,  1.08s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  57%|█████████████████████████████████████████████▌                                  | 326/573 [05:51<04:26,  1.08s/it, loss=0.362, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  57%|█████████████████████████████████████████████▊                                  | 328/573 [05:53<04:23,  1.08s/it, loss=0.365, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  58%|██████████████████████████████████████████████▋                                  | 330/573 [05:55<04:21,  1.08s/it, loss=0.37, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  58%|██████████████████████████████████████████████▎                                 | 332/573 [05:57<04:19,  1.08s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  58%|██████████████████████████████████████████████▋                                 | 334/573 [05:59<04:17,  1.08s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  58%|███████████████████████████████████████████████▏                                 | 334/573 [05:59<04:17,  1.08s/it, loss=0.35, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  59%|██████████████████████████████████████████████▉                                 | 336/573 [06:01<04:15,  1.08s/it, loss=0.345, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  59%|███████████████████████████████████████████████▏                                | 338/573 [06:03<04:12,  1.08s/it, loss=0.346, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  59%|███████████████████████████████████████████████▍                                | 340/573 [06:05<04:10,  1.08s/it, loss=0.349, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  60%|███████████████████████████████████████████████▋                                | 342/573 [06:07<04:08,  1.08s/it, loss=0.346, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  60%|████████████████████████████████████████████████▋                                | 344/573 [06:09<04:06,  1.08s/it, loss=0.34, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  60%|████████████████████████████████████████████████▎                               | 346/573 [06:11<04:04,  1.07s/it, loss=0.336, v_num=zk13, train categorical_accuracy_step=0.750, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  61%|████████████████████████████████████████████████▌                               | 348/573 [06:13<04:01,  1.07s/it, loss=0.334, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  61%|█████████████████████████████████████████████████▍                               | 350/573 [06:15<03:59,  1.07s/it, loss=0.33, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  61%|█████████████████████████████████████████████████▏                              | 352/573 [06:17<03:57,  1.07s/it, loss=0.331, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  62%|█████████████████████████████████████████████████▍                              | 354/573 [06:20<03:55,  1.07s/it, loss=0.331, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  62%|█████████████████████████████████████████████████▋                              | 356/573 [06:22<03:52,  1.07s/it, loss=0.331, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  62%|█████████████████████████████████████████████████▉                              | 358/573 [06:24<03:50,  1.07s/it, loss=0.331, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  63%|██████████████████████████████████████████████████▎                             | 360/573 [06:26<03:48,  1.07s/it, loss=0.334, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  63%|██████████████████████████████████████████████████▌                             | 362/573 [06:28<03:46,  1.07s/it, loss=0.342, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  64%|██████████████████████████████████████████████████▊                             | 364/573 [06:30<03:44,  1.07s/it, loss=0.351, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  64%|███████████████████████████████████████████████████                             | 366/573 [06:32<03:42,  1.07s/it, loss=0.353, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  64%|███████████████████████████████████████████████████▍                            | 368/573 [06:35<03:40,  1.07s/it, loss=0.352, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  65%|███████████████████████████████████████████████████▋                            | 370/573 [06:37<03:37,  1.07s/it, loss=0.356, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  65%|███████████████████████████████████████████████████▉                            | 372/573 [06:39<03:35,  1.07s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  65%|████████████████████████████████████████████████████▏                           | 374/573 [06:41<03:33,  1.07s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  66%|████████████████████████████████████████████████████▍                           | 376/573 [06:43<03:31,  1.07s/it, loss=0.362, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  66%|████████████████████████████████████████████████████▊                           | 378/573 [06:45<03:29,  1.07s/it, loss=0.355, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  66%|█████████████████████████████████████████████████████                           | 380/573 [06:47<03:26,  1.07s/it, loss=0.356, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  67%|█████████████████████████████████████████████████████▎                          | 382/573 [06:49<03:24,  1.07s/it, loss=0.345, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.931]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  67%|█████████████████████████████████████████████████████▌                          | 384/573 [06:51<03:22,  1.07s/it, loss=0.345, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  67%|█████████████████████████████████████████████████████▉                          | 386/573 [06:53<03:20,  1.07s/it, loss=0.338, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  68%|██████████████████████████████████████████████████████▏                         | 388/573 [06:55<03:18,  1.07s/it, loss=0.339, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  68%|██████████████████████████████████████████████████████▍                         | 390/573 [06:57<03:16,  1.07s/it, loss=0.344, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  68%|██████████████████████████████████████████████████████▋                         | 392/573 [06:59<03:13,  1.07s/it, loss=0.338, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  68%|██████████████████████████████████████████████████████▋                         | 392/573 [06:59<03:13,  1.07s/it, loss=0.338, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  69%|███████████████████████████████████████████████████████                         | 394/573 [07:01<03:11,  1.07s/it, loss=0.348, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.792]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  69%|███████████████████████████████████████████████████████▎                        | 396/573 [07:03<03:09,  1.07s/it, loss=0.354, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  69%|███████████████████████████████████████████████████████▌                        | 398/573 [07:06<03:07,  1.07s/it, loss=0.361, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  70%|███████████████████████████████████████████████████████▊                        | 400/573 [07:08<03:05,  1.07s/it, loss=0.361, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  70%|████████████████████████████████████████████████████████▏                       | 402/573 [07:10<03:02,  1.07s/it, loss=0.364, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  71%|████████████████████████████████████████████████████████▍                       | 404/573 [07:12<03:00,  1.07s/it, loss=0.358, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  71%|████████████████████████████████████████████████████████▋                       | 406/573 [07:14<02:58,  1.07s/it, loss=0.367, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  71%|████████████████████████████████████████████████████████▉                       | 408/573 [07:16<02:56,  1.07s/it, loss=0.368, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  72%|█████████████████████████████████████████████████████████▏                      | 410/573 [07:18<02:54,  1.07s/it, loss=0.364, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  72%|█████████████████████████████████████████████████████████▌                      | 412/573 [07:20<02:52,  1.07s/it, loss=0.363, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  72%|█████████████████████████████████████████████████████████▊                      | 414/573 [07:22<02:50,  1.07s/it, loss=0.354, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  73%|██████████████████████████████████████████████████████████                      | 416/573 [07:25<02:48,  1.07s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  73%|██████████████████████████████████████████████████████████▎                     | 418/573 [07:27<02:45,  1.07s/it, loss=0.349, v_num=zk13, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  73%|██████████████████████████████████████████████████████████▋                     | 420/573 [07:29<02:43,  1.07s/it, loss=0.342, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  74%|██████████████████████████████████████████████████████████▉                     | 422/573 [07:31<02:41,  1.07s/it, loss=0.349, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  74%|██████████████████████████████████████████████████████████▉                     | 422/573 [07:31<02:41,  1.07s/it, loss=0.349, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  74%|███████████████████████████████████████████████████████████▏                    | 424/573 [07:33<02:39,  1.07s/it, loss=0.347, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  74%|███████████████████████████████████████████████████████████▍                    | 426/573 [07:36<02:37,  1.07s/it, loss=0.336, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.889]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  75%|███████████████████████████████████████████████████████████▊                    | 428/573 [07:38<02:35,  1.07s/it, loss=0.335, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.778]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  75%|████████████████████████████████████████████████████████████                    | 430/573 [07:40<02:33,  1.07s/it, loss=0.334, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  75%|████████████████████████████████████████████████████████████▎                   | 432/573 [07:42<02:30,  1.07s/it, loss=0.345, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  76%|████████████████████████████████████████████████████████████▌                   | 434/573 [07:44<02:28,  1.07s/it, loss=0.338, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  76%|████████████████████████████████████████████████████████████▊                   | 436/573 [07:46<02:26,  1.07s/it, loss=0.332, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.833]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  76%|█████████████████████████████████████████████████████████████▏                  | 438/573 [07:48<02:24,  1.07s/it, loss=0.326, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.500, train binary_accuracy_step=0.903]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  77%|██████████████████████████████████████████████████████████████▏                  | 440/573 [07:50<02:22,  1.07s/it, loss=0.33, v_num=zk13, train categorical_accuracy_step=0.625, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.819]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  77%|██████████████████████████████████████████████████████████████▍                  | 442/573 [07:52<02:20,  1.07s/it, loss=0.33, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.847]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  77%|█████████████████████████████████████████████████████████████▉                  | 444/573 [07:54<02:17,  1.07s/it, loss=0.335, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.000, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  78%|██████████████████████████████████████████████████████████████▎                 | 446/573 [07:56<02:15,  1.07s/it, loss=0.347, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.806]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  78%|██████████████████████████████████████████████████████████████▌                 | 448/573 [07:58<02:13,  1.07s/it, loss=0.348, v_num=zk13, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  79%|███████████████████████████████████████████████████████████████▌                 | 450/573 [08:01<02:11,  1.07s/it, loss=0.35, v_num=zk13, train categorical_accuracy_step=0.375, train categorical_accuracy_strict_step=0.250, train binary_accuracy_step=0.861]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  79%|███████████████████████████████████████████████████████████████                 | 452/573 [08:03<02:09,  1.07s/it, loss=0.341, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.764]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  79%|███████████████████████████████████████████████████████████████▍                | 454/573 [08:05<02:07,  1.07s/it, loss=0.348, v_num=zk13, train categorical_accuracy_step=0.250, train categorical_accuracy_strict_step=0.125, train binary_accuracy_step=0.875]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  80%|███████████████████████████████████████████████████████████████▋                | 456/573 [08:07<02:05,  1.07s/it, loss=0.339, v_num=zk13, train categorical_accuracy_step=0.125, train categorical_accuracy_strict_step=0.375, train binary_accuracy_step=0.917]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  80%|███████████████████████████████████████████████████████████████▉                | 458/573 [08:09<02:02,  1.07s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  80%|████████████████████████████████████████████████████████████████▏               | 460/573 [08:11<02:00,  1.07s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  81%|████████████████████████████████████████████████████████████████▌               | 462/573 [08:13<01:58,  1.07s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  81%|████████████████████████████████████████████████████████████████▊               | 464/573 [08:14<01:56,  1.07s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  81%|█████████████████████████████████████████████████████████████████               | 466/573 [08:16<01:54,  1.07s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  82%|█████████████████████████████████████████████████████████████████▎              | 468/573 [08:18<01:51,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  82%|█████████████████████████████████████████████████████████████████▉              | 472/573 [08:21<01:47,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  83%|██████████████████████████████████████████████████████████████████▏             | 474/573 [08:23<01:45,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  83%|██████████████████████████████████████████████████████████████████▍             | 476/573 [08:24<01:42,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  83%|██████████████████████████████████████████████████████████████████▋             | 478/573 [08:26<01:40,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  84%|███████████████████████████████████████████████████████████████████             | 480/573 [08:28<01:38,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  84%|███████████████████████████████████████████████████████████████████▌            | 484/573 [08:31<01:34,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  85%|███████████████████████████████████████████████████████████████████▊            | 486/573 [08:33<01:31,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  85%|████████████████████████████████████████████████████████████████████▏           | 488/573 [08:35<01:29,  1.06s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  86%|████████████████████████████████████████████████████████████████████▍           | 490/573 [08:36<01:27,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  86%|████████████████████████████████████████████████████████████████████▋           | 492/573 [08:38<01:25,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  87%|█████████████████████████████████████████████████████████████████████▏          | 496/573 [08:42<01:21,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  87%|█████████████████████████████████████████████████████████████████████▌          | 498/573 [08:43<01:18,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  87%|█████████████████████████████████████████████████████████████████████▊          | 500/573 [08:45<01:16,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  88%|██████████████████████████████████████████████████████████████████████          | 502/573 [08:47<01:14,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  88%|██████████████████████████████████████████████████████████████████████▎         | 504/573 [08:49<01:12,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  88%|██████████████████████████████████████████████████████████████████████▋         | 506/573 [08:50<01:10,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  89%|███████████████████████████████████████████████████████████████████████▏        | 510/573 [08:54<01:05,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  89%|███████████████████████████████████████████████████████████████████████▏        | 510/573 [08:54<01:05,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  90%|███████████████████████████████████████████████████████████████████████▊        | 514/573 [08:57<01:01,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  90%|████████████████████████████████████████████████████████████████████████        | 516/573 [08:59<00:59,  1.05s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  90%|████████████████████████████████████████████████████████████████████████▎       | 518/573 [09:01<00:57,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  91%|████████████████████████████████████████████████████████████████████████▌       | 520/573 [09:02<00:55,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  91%|████████████████████████████████████████████████████████████████████████▉       | 522/573 [09:04<00:53,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  91%|█████████████████████████████████████████████████████████████████████████▏      | 524/573 [09:06<00:51,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  92%|█████████████████████████████████████████████████████████████████████████▋      | 528/573 [09:09<00:46,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  92%|█████████████████████████████████████████████████████████████████████████▉      | 530/573 [09:11<00:44,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  93%|██████████████████████████████████████████████████████████████████████████▎     | 532/573 [09:12<00:42,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  93%|██████████████████████████████████████████████████████████████████████████▌     | 534/573 [09:14<00:40,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  94%|███████████████████████████████████████████████████████████████████████████     | 538/573 [09:18<00:36,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  94%|███████████████████████████████████████████████████████████████████████████▍    | 540/573 [09:19<00:34,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  95%|███████████████████████████████████████████████████████████████████████████▋    | 542/573 [09:21<00:32,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  95%|███████████████████████████████████████████████████████████████████████████▉    | 544/573 [09:23<00:30,  1.04s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  95%|████████████████████████████████████████████████████████████████████████████▏   | 546/573 [09:25<00:27,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  96%|████████████████████████████████████████████████████████████████████████████▌   | 548/573 [09:26<00:25,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  96%|█████████████████████████████████████████████████████████████████████████████   | 552/573 [09:30<00:21,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 554/573 [09:32<00:19,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  97%|█████████████████████████████████████████████████████████████████████████████▋  | 556/573 [09:33<00:17,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  97%|█████████████████████████████████████████████████████████████████████████████▉  | 558/573 [09:35<00:15,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  98%|██████████████████████████████████████████████████████████████████████████████▏ | 560/573 [09:37<00:13,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  98%|██████████████████████████████████████████████████████████████████████████████▍ | 562/573 [09:38<00:11,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  99%|███████████████████████████████████████████████████████████████████████████████ | 566/573 [09:42<00:07,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  99%|███████████████████████████████████████████████████████████████████████████████▎| 568/573 [09:44<00:05,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0:  99%|███████████████████████████████████████████████████████████████████████████████▌| 570/573 [09:45<00:03,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([8, 256, 8000])
Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train categorical_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train categorical_accuracy_strict', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train binary_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
[rank: 0] Metric val_loss improved. New best score: 0.331
Epoch 0, global step 458: 'val_loss' reached 0.33095 (best 0.33095), saving model to '/home/sxr280/BERTLocRNA/output/RNAlocalization/parnet/checkpoints/checkpoints_best-v1.ckpt' as top 1
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
`Trainer.fit` stopped: `max_epochs=1` reached.
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])███████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
embed_output shape: torch.Size([8, 256, 8000])])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
input embedding shape torch.Size([8, 256, 8000])█████████████████████████████████████████████▊| 572/573 [09:47<00:01,  1.03s/it, loss=0.357, v_num=zk13, train categorical_accuracy_step=0.286, train categorical_accuracy_strict_step=0.143, train binary_accuracy_step=0.762]input embedding shape torch.Size([6, 256, 8000])
Traceback (most recent call last):
  File "train_model.py", line 55, in <module>
    train()
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 465, in _run_app
    run_and_report(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 219, in run_and_report
    return func()
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 466, in <lambda>
    lambda: hydra.multirun(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 162, in multirun
    ret = sweeper.sweep(arguments=task_overrides)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/core_plugins/basic_sweeper.py", line 178, in sweep
    results = self.launcher.launch(batch, initial_job_idx=initial_job_idx)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/core_plugins/basic_launcher.py", line 74, in launch
    ret = run_job(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "train_model.py", line 52, in train
    Trainer.test(test_dataloader)
  File "/home/sxr280/BERTLocRNA/scripts/../utils/trainer.py", line 262, in test
    self.get_metrics_all(test_loader)
  File "/home/sxr280/BERTLocRNA/scripts/../utils/trainer.py", line 271, in get_metrics_all
    y_pred = self.plmodel.forward(X_test, X_mask, RNA_type)
  File "/home/sxr280/BERTLocRNA/scripts/../../BERTLocRNA/models/base_model.py", line 89, in forward
  File "/home/sxr280/BERTLocRNA/scripts/../../BERTLocRNA/models/base_model.py", line 75, in Att
    self.att_weight = att1_A
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sxr280/BERTLocRNA/scripts/../../BERTLocRNA/models/attention.py", line 43, in forward
    s = torch.sum(_at, dim=1, keepdim=True)
KeyboardInterrupt