ok
/home/sxr280/BERTLocRNA/scripts
main function initialization:
name of the model parameters: fc1.weight
name of the model parameters: fc1.bias
name of the model parameters: fc2.weight
name of the model parameters: fc2.bias
name of the model parameters: embedding_layer.weight
name of the model parameters: Attention_layer.W1.weight
name of the model parameters: Attention_layer.W2.weight
embedding will be saved at: /home/sxr280/BERTLocRNA/embeddings/Parnetembedding
loading the dataset...
Resolving data files: 100%|███████████████████████████████████████████████████████████████████████████| 243/243 [00:00<00:00, 206905.37it/s]
Resolving data files: 100%|██████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 92973.49it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████| 77/77 [00:00<00:00, 204924.75it/s]
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
after initialization:
name of the model parameters: network.fc1.weight
name of the model parameters: network.fc1.bias
name of the model parameters: network.fc2.weight
name of the model parameters: network.fc2.bias
name of the model parameters: network.embedding_layer.weight
name of the model parameters: network.Attention_layer.W1.weight
name of the model parameters: network.Attention_layer.W2.weight
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python train_model.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/sxr280/BERTLocRNA/output/RNAlocalization/parnet/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name    | Type            | Params
--------------------------------------------
0 | network | CustomizedModel | 98.6 K
1 | loss_fn | BCELoss         | 0
--------------------------------------------
98.6 K    Trainable params
0         Non-trainable params
98.6 K    Total params
0.395     Total estimated model params size (MB)
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val categorical_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val categorical_accuracy_strict', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val binary_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
LightningModel                           [2, 9]                    --
├─CustomizedModel: 1-1                   [2, 9]                    --
│    └─Attention_mask: 2-1               [2, 256, 3]               --
│    │    └─Linear: 3-1                  [2, 8000, 80]             20,480
│    │    └─Tanh: 3-2                    [2, 8000, 80]             --
│    │    └─Linear: 3-3                  [2, 8000, 3]              240
│    └─Flatten: 2-2                      [2, 768]                  --
│    └─Embedding: 2-3                    [2, 4]                    76
│    └─Linear: 2-4                       [2, 100]                  76,900
│    └─Actvation: 2-5                    [2, 104]                  --
│    └─Dropout: 2-6                      [2, 104]                  --
│    └─Linear: 2-7                       [2, 9]                    945
│    └─Sigmoid: 2-8                      [2, 9]                    --
==========================================================================================
Total params: 98,641
Trainable params: 98,641
Non-trainable params: 0
Total mult-adds (M): 0.20
==========================================================================================
Input size (MB): 16.45
Forward/backward pass size (MB): 10.63
Params size (MB): 0.39
Estimated Total Size (MB): 27.47
==========================================================================================
[2023-12-04 00:22:12,876][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2023-12-04 00:22:12,876][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.






















































































































































































































































Epoch 0:  80%|▊| 1832/2291 [08:15<02:04,  3.70it/s, loss=0.332, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accurac














































Validation DataLoader 0:  98%|██████████████████████████████████████████████████████████████████████████▋ | 451/459 [01:29<00:01,  5.01it/s]
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train categorical_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train categorical_accuracy_strict', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('train binary_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
Metric val_loss improved. New best score: 0.319
Epoch 0: 100%|█| 2291/2291 [09:47<00:00,  3.90it/s, loss=0.332, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accuracEpoch duration: 587.94 seconds










































































































































































































































Epoch 1:  80%|▊| 1832/2291 [07:54<01:58,  3.86it/s, loss=0.337, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accurac














































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▌| 456/459 [01:32<00:00,  4.96it/s]




































































































































































































































Epoch 2:  80%|▊| 1838/2291 [07:38<01:52,  4.01it/s, loss=0.303, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accurac















































Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████| 459/459 [01:35<00:00,  4.79it/s]


































































































































































































































Epoch 3:  80%|▊| 1832/2291 [07:34<01:53,  4.03it/s, loss=0.333, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accurac
















































Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████▊| 458/459 [01:34<00:00,  4.87it/s]
Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.310
Epoch 3: 100%|█| 2291/2291 [09:09<00:00,  4.17it/s, loss=0.333, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accuracEpoch duration: 549.96 seconds









































































































































































































































Epoch 4:  80%|▊| 1834/2291 [07:52<01:57,  3.88it/s, loss=0.31, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuracy















































Validation DataLoader 0:  98%|██████████████████████████████████████████████████████████████████████████▋ | 451/459 [01:34<00:01,  4.79it/s]
Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.306

Epoch 4: 100%|█| 2291/2291 [09:27<00:00,  4.04it/s, loss=0.31, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuracyEpoch duration: 568.15 seconds

































































































































































































































Epoch 5:  80%|▊| 1834/2291 [07:36<01:53,  4.01it/s, loss=0.325, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accurac















































Validation DataLoader 0:  98%|██████████████████████████████████████████████████████████████████████████▎ | 449/459 [01:32<00:02,  4.84it/s]
Epoch 5: 100%|█| 2291/2291 [09:11<00:00,  4.15it/s, loss=0.325, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accuracEpoch duration: 551.47 seconds

















































































































































































































































Epoch 6:  80%|▊| 1832/2291 [08:06<02:01,  3.76it/s, loss=0.327, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accurac


















































Epoch 7:   0%| | 2/2291 [00:00<09:54,  3.85it/s, loss=0.325, v_num=518a, train categorical_accuracy_step=0.125, train categorical_accuracy_s




















































































































































































































































Epoch 7:  80%|▊| 1839/2291 [08:11<02:00,  3.74it/s, loss=0.347, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accurac


















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▎| 455/459 [01:41<00:00,  4.50it/s]
Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.303

Epoch 7: 100%|█| 2291/2291 [09:52<00:00,  3.87it/s, loss=0.347, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accuracEpoch duration: 592.57 seconds



























































































































































































































































Epoch 8:  80%|▊| 1837/2291 [08:30<02:06,  3.60it/s, loss=0.34, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuracy






















































Epoch 9:   0%| | 1/2291 [00:00<11:02,  3.46it/s, loss=0.338, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuracy_s











































































































































































































































































Epoch 9:  80%|▊| 1832/2291 [08:57<02:14,  3.41it/s, loss=0.305, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accurac
















































Epoch 10:   0%| | 1/2291 [00:00<11:57,  3.19it/s, loss=0.305, v_num=518a, train categorical_accuracy_step=0.625, train categorical_accuracy_




































































































































































































































































Epoch 10:  80%|▊| 1834/2291 [08:43<02:10,  3.50it/s, loss=0.336, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura





















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▌| 456/459 [01:46<00:00,  4.28it/s]
















































































































































































































































Epoch 11:  80%|▊| 1836/2291 [08:02<01:59,  3.80it/s, loss=0.331, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura



















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▏| 454/459 [01:42<00:01,  4.42it/s]
Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.303

Epoch 11: 100%|█| 2291/2291 [09:45<00:00,  3.91it/s, loss=0.331, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuraEpoch duration: 586.20 seconds
































































































































































































































































Epoch 12:  80%|▊| 1832/2291 [08:39<02:10,  3.53it/s, loss=0.344, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accura



















































Epoch 13:   0%| | 0/2291 [00:00<?, ?it/s, loss=0.344, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_s




































































































































































































































































Epoch 13:  80%|▊| 1837/2291 [08:43<02:09,  3.51it/s, loss=0.315, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura











































Epoch 14:   0%| | 1/2291 [00:00<13:04,  2.92it/s, loss=0.323, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accuracy_











































































































































































































































































Epoch 14:  80%|▊| 1835/2291 [08:57<02:13,  3.41it/s, loss=0.328, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura



















































Epoch 15:   0%| | 3/2291 [00:01<13:05,  2.91it/s, loss=0.312, v_num=518a, train categorical_accuracy_step=0.125, train categorical_accuracy_


































































































































































































































































Epoch 15:  80%|▊| 1832/2291 [08:40<02:10,  3.52it/s, loss=0.285, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura




















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▌| 456/459 [01:43<00:00,  4.40it/s]

Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.301
Epoch 15: 100%|█| 2291/2291 [10:24<00:00,  3.67it/s, loss=0.285, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuraEpoch duration: 625.02 seconds




























































































































































































































































Epoch 16:  80%|▊| 1836/2291 [08:31<02:06,  3.59it/s, loss=0.303, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accura

















































Validation DataLoader 0:  98%|██████████████████████████████████████████████████████████████████████████▏ | 448/459 [01:38<00:02,  4.53it/s]










































































































































































































































































Epoch 17:  80%|▊| 1838/2291 [08:53<02:11,  3.45it/s, loss=0.297, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accura
























































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▌| 456/459 [01:53<00:00,  4.02it/s]












































































































































































































































































Epoch 18:  80%|▊| 1841/2291 [08:58<02:11,  3.42it/s, loss=0.308, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura






















































Validation DataLoader 0:  98%|██████████████████████████████████████████████████████████████████████████▊ | 452/459 [01:47<00:01,  4.20it/s]
Epoch 18: 100%|█| 2291/2291 [10:46<00:00,  3.54it/s, loss=0.308, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuraEpoch duration: 646.54 seconds















































































































































































































































































Epoch 19:  80%|▊| 1837/2291 [09:06<02:15,  3.36it/s, loss=0.351, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura

















































Epoch 20:   0%| | 0/2291 [00:00<?, ?it/s, loss=0.351, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuracy_strict_s























































































































































































































































































Epoch 20:  80%|▊| 1834/2291 [09:21<02:19,  3.27it/s, loss=0.312, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accura





















































Epoch 21:   0%| | 0/2291 [00:00<?, ?it/s, loss=0.312, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accuracy_strict_s
















































































































































































































































































Epoch 21:  80%|▊| 1838/2291 [09:07<02:14,  3.36it/s, loss=0.346, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura























































Epoch 22:   0%| | 5/2291 [00:01<10:20,  3.68it/s, loss=0.34, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuracy_s

































































































































































































































































Epoch 22:  80%|▊| 1838/2291 [08:38<02:07,  3.54it/s, loss=0.29, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accurac
















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▎| 455/459 [01:36<00:00,  4.70it/s]












































































































































































































































































Epoch 23:  80%|▊| 1836/2291 [08:57<02:13,  3.41it/s, loss=0.313, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura



















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▏| 454/459 [01:42<00:01,  4.42it/s]











































































































































































































































































Epoch 24:  80%|▊| 1837/2291 [08:55<02:12,  3.43it/s, loss=0.342, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura


















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████ | 453/459 [01:41<00:01,  4.48it/s]













































































































































































































































































Epoch 25:  80%|▊| 1835/2291 [08:59<02:14,  3.40it/s, loss=0.316, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accura






















































Epoch 26:   0%| | 0/2291 [00:00<?, ?it/s, loss=0.316, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accuracy_strict_s







































































































































































































































































Epoch 26:  80%|▊| 1832/2291 [08:49<02:12,  3.46it/s, loss=0.331, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accura
























































Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████▋| 457/459 [01:51<00:00,  4.09it/s]








































































































































































































































































Epoch 27:  80%|▊| 1837/2291 [08:50<02:11,  3.46it/s, loss=0.334, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accura





















































Epoch 28:   0%| | 4/2291 [00:01<12:35,  3.03it/s, loss=0.323, v_num=518a, train categorical_accuracy_step=0.375, train categorical_accuracy_











































































































































































































































































Epoch 28:  80%|▊| 1832/2291 [08:58<02:14,  3.40it/s, loss=0.306, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accura


















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▎| 455/459 [01:40<00:00,  4.54it/s]














































































































































































































































































Epoch 29:  80%|▊| 1834/2291 [09:02<02:15,  3.38it/s, loss=0.312, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura





















































Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████| 459/459 [01:46<00:00,  4.32it/s]






































































































































































































































































Epoch 30:  80%|▊| 1836/2291 [08:46<02:10,  3.48it/s, loss=0.291, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura





















































Validation DataLoader 0:  99%|███████████████████████████████████████████████████████████████████████████▌| 456/459 [01:47<00:00,  4.24it/s]















































































































































































































































Epoch 31:  80%|▊| 1838/2291 [08:00<01:58,  3.83it/s, loss=0.34, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accurac





















































Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████▊| 458/459 [01:47<00:00,  4.26it/s]










































































































































































































































































Epoch 32:  80%|▊| 1838/2291 [08:54<02:11,  3.44it/s, loss=0.308, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accura



















































Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████▊| 458/459 [01:43<00:00,  4.43it/s]






















































































































































































































































Epoch 33:  80%|▊| 1836/2291 [08:15<02:02,  3.71it/s, loss=0.325, v_num=518a, train categorical_accuracy_step=1.000, train categorical_accura

















































Epoch 34:   0%| | 1/2291 [00:00<10:26,  3.65it/s, loss=0.337, v_num=518a, train categorical_accuracy_step=0.125, train categorical_accuracy_






































































































































































































































































Epoch 34:  80%|▊| 1839/2291 [08:47<02:09,  3.49it/s, loss=0.333, v_num=518a, train categorical_accuracy_step=0.000, train categorical_accura

















































Validation DataLoader 0:  98%|██████████████████████████████████████████████████████████████████████████▎ | 449/459 [01:39<00:02,  4.52it/s]










































































































































































































































































Epoch 35:  80%|▊| 1834/2291 [08:52<02:12,  3.44it/s, loss=0.324, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura

















































Validation DataLoader 0:  98%|██████████████████████████████████████████████████████████████████████████▏ | 448/459 [01:36<00:02,  4.65it/s]
Monitored metric val_loss did not improve in the last 20 records. Best score: 0.301. Signaling Trainer to stop.
Epoch 35: 100%|█| 2291/2291 [10:31<00:00,  3.63it/s, loss=0.324, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accuraEpoch duration: 631.52 seconds
Epoch 35: 100%|█| 2291/2291 [10:31<00:00,  3.63it/s, loss=0.324, v_num=518a, train categorical_accuracy_step=0.500, train categorical_accura
[2023-12-04 06:32:25,751][HYDRA] 	#1 : model=base_model task=RNAlocalization embedder=nucleotidetransformer
output dir of this job: /home/sxr280/BERTLocRNA/scripts/../output/RNAlocalization/nucleotidetransformer
main function initialization:
name of the model parameters: fc1.weight
name of the model parameters: fc1.bias
name of the model parameters: fc2.weight
name of the model parameters: fc2.bias
name of the model parameters: embedding_layer.weight
name of the model parameters: Attention_layer.W1.weight
name of the model parameters: Attention_layer.W2.weight
/home/sxr280/BERTLocRNA/saved_model/NT  already exists, loading the model locally
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:21<00:00, 10.95s/it]
Some weights of the model checkpoint at /home/sxr280/BERTLocRNA/saved_model/NT were not used when initializing EsmModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of EsmModel were not initialized from the model checkpoint at /home/sxr280/BERTLocRNA/saved_model/NT and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Resolving data files: 100%|███████████████████████████████████████████████████████████████████████████| 296/296 [00:00<00:00, 259459.56it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 155191.32it/s]
Resolving data files: 100%|█████████████████████████████████████████████████████████████████████████████| 94/94 [00:00<00:00, 157642.77it/s]
loading the dataset...
Error executing job with overrides: ['model=base_model', 'task=RNAlocalization', 'embedder=parnet']
Traceback (most recent call last):
  File "train_model.py", line 57, in <module>
    train()
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 465, in _run_app
    run_and_report(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 222, in run_and_report
    raise ex
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 219, in run_and_report
    return func()
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/utils.py", line 466, in <lambda>
    lambda: hydra.multirun(
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 162, in multirun
    ret = sweeper.sweep(arguments=task_overrides)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/_internal/core_plugins/basic_sweeper.py", line 182, in sweep
    _ = r.return_value
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "train_model.py", line 54, in train
    Trainer.test(test_dataloader)
  File "/home/sxr280/BERTLocRNA/scripts/../utils/trainer.py", line 270, in test
    self.get_metrics_all(test_loader)
  File "/home/sxr280/BERTLocRNA/scripts/../utils/trainer.py", line 279, in get_metrics_all
    y_pred = self.plmodel.forward(X_test, X_mask, RNA_type)
  File "/home/sxr280/BERTLocRNA/scripts/../utils/trainer.py", line 113, in forward
    pred = self.network(embed, mask, RNA_type)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sxr280/BERTLocRNA/scripts/../../BERTLocRNA/models/base_model.py", line 92, in forward
    output = self.Att(embed, x_mask) #[hidden, heads]
  File "/home/sxr280/BERTLocRNA/scripts/../../BERTLocRNA/models/base_model.py", line 79, in Att
    att1,att1_A = self.Attention_layer(embed_output, masks = True)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sxr280/BERTLocRNA/scripts/../../BERTLocRNA/models/attention.py", line 35, in forward
    H_t = self.activation(self.W1(H1_t)) # (b, length, att_dim)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sxr280/miniconda3/envs/deeploc_torch/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)
after initialization:
name of the model parameters: network.fc1.weight
name of the model parameters: network.fc1.bias
name of the model parameters: network.fc2.weight
name of the model parameters: network.fc2.bias
name of the model parameters: network.embedding_layer.weight
name of the model parameters: network.Attention_layer.W1.weight
name of the model parameters: network.Attention_layer.W2.weight